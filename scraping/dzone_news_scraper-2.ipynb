{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94sjOg4JttQC","executionInfo":{"status":"ok","timestamp":1729454196463,"user_tz":180,"elapsed":11136,"user":{"displayName":"Fernando Muraca","userId":"00342931229691733138"}},"outputId":"43ad335a-98a4-426f-fb4c-17d88dee1197"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"]}],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Slgo8aWUtud1","executionInfo":{"status":"ok","timestamp":1729454206130,"user_tz":180,"elapsed":2378,"user":{"displayName":"Fernando Muraca","userId":"00342931229691733138"}}},"outputs":[],"source":["# Importar las bibliotecas necesarias\n","import requests\n","from bs4 import BeautifulSoup\n","\n","from google.colab import drive\n","import time\n","import random\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwk-iRx-twOL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729375923881,"user_tz":180,"elapsed":2004371,"user":{"displayName":"Fernando Muraca","userId":"00342931229691733138"}},"outputId":"e390617e-fcd2-414e-95c2-89753406bf78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["Scraping Progress: 100%|█████████▉| 647/648 [32:30<00:03,  3.01s/it, Page: 648, URL: https://dzone.com/software-design-and-architecture/648]\n"]},{"output_type":"stream","name":"stdout","text":["Scraping completo. CSV guardado en: /content/drive/MyDrive/dzone_software_design_architecture.csv\n","                                               Title  \\\n","0  Serverless Computing and GraphQL: Modern App D...   \n","1  CI/CD Pipelines in the Cloud: How Cloud Hostin...   \n","2  What We Learned About Secrets Security at AppS...   \n","3  Mutable vs. Immutable: Infrastructure Models i...   \n","4               An Overview of TCPCopy for Beginners   \n","\n","                                                 URL  \\\n","0  https://dzone.com/articles/serverless-computin...   \n","1  https://dzone.com/articles/cicd-pipelines-in-t...   \n","2  https://dzone.com/articles/secrets-security-at...   \n","3  https://dzone.com/articles/infrastructure-mode...   \n","4  https://dzone.com/articles/an-overview-of-tcpc...   \n","\n","                                              Detail              Date  \\\n","0  In this step-by-step guide, learn how to defin...  October 14, 2024   \n","1  Cloud-hosted CI/CD pipelines enhance software ...  October 14, 2024   \n","2  Learn about DEF CON 32: AppSec Village, explor...  October 14, 2024   \n","3  Explore mutable infrastructure and immutable s...  October 14, 2024   \n","4  In this article, learn more about TCPCopy, an ...  October 11, 2024   \n","\n","                     Author        Views  \n","0  balaji thadagam kandavel  2,860 Views  \n","1             Anton Lucanus  2,217 Views  \n","2           Dwayne McDaniel  2,051 Views  \n","3  Josephine Eskaline Joyce  3,647 Views  \n","4                  Bin Wang  3,245 Views  \n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 12923 entries, 0 to 12922\n","Data columns (total 6 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   Title   12923 non-null  object\n"," 1   URL     12923 non-null  object\n"," 2   Detail  12923 non-null  object\n"," 3   Date    12923 non-null  object\n"," 4   Author  12923 non-null  object\n"," 5   Views   12923 non-null  object\n","dtypes: object(6)\n","memory usage: 605.9+ KB\n","None\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","import random\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Función para extraer información de una tarjeta\n","def extract_card_info(card):\n","    title_element = card.select_one('.article-title')\n","    title = title_element.text.strip()\n","    url = \"https://dzone.com\" + title_element['href']\n","    detail = card.select_one('.article-desc').text.strip()\n","    date = card.select_one('.article-date').contents[0].strip()\n","    author = card.select_one('.article-author').text.strip()\n","    views = card.select_one('.article-stats').text.split('·')[1].strip()\n","    return {\n","        'Title': title,\n","        'URL': url,\n","        'Detail': detail,\n","        'Date': date,\n","        'Author': author,\n","        'Views': views\n","    }\n","\n","def scrape_dzone():\n","    base_url = \"https://dzone.com/software-design-and-architecture/\"\n","    csv_path = '/content/drive/MyDrive/dzone_software_design_architecture.csv'\n","\n","    # Verificar si el CSV existe y obtener la última página procesada\n","    try:\n","        df_existing = pd.read_csv(csv_path)\n","        last_processed_page = len(df_existing) // 25 + 1\n","    except FileNotFoundError:\n","        last_processed_page = 2\n","\n","    # Calcular el número total de páginas\n","    total_pages = 648\n","\n","    # Crear la barra de progreso\n","    with tqdm(total=total_pages, initial=last_processed_page-2, desc=\"Scraping Progress\") as pbar:\n","        for page in range(last_processed_page, total_pages + 1):\n","            url = f\"{base_url}{page}\"\n","\n","            try:\n","                response = requests.get(url)\n","                response.raise_for_status()\n","                soup = BeautifulSoup(response.content, 'html.parser')\n","\n","                cards = soup.select('div.media')\n","\n","                page_data = []\n","                for card in cards:\n","                    card_info = extract_card_info(card)\n","                    page_data.append(card_info)\n","\n","                # Convertir los datos de la página a DataFrame\n","                df_page = pd.DataFrame(page_data)\n","\n","                # Guardar o anexar al CSV\n","                if page == 2 and last_processed_page == 2:\n","                    df_page.to_csv(csv_path, index=False, mode='w')\n","                else:\n","                    df_page.to_csv(csv_path, index=False, mode='a', header=False)\n","\n","                # Actualizar la barra de progreso con información adicional\n","                pbar.set_postfix_str(f\"Page: {page}, URL: {url}\")\n","                pbar.update(1)\n","\n","            except Exception as e:\n","                print(f\"Error processing page {url}: {e}\")\n","\n","            # Pausa aleatoria para evitar sobrecarga del servidor\n","            time.sleep(random.uniform(1, 3))\n","\n","    print(f\"Scraping completo. CSV guardado en: {csv_path}\")\n","\n","# Ejecutar el scraping\n","scrape_dzone()\n","\n","# Cargar el CSV final y mostrar información\n","df = pd.read_csv('/content/drive/MyDrive/dzone_software_design_architecture.csv')\n","\n","# Mostrar las primeras filas del DataFrame\n","print(df.head())\n","\n","# Mostrar información sobre el DataFrame\n","print(df.info())"]},{"cell_type":"code","source":["# Montar Google Drive\n","from google.colab import drive\n","import pandas as pd\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Ruta del archivo CSV original en Google Drive\n","csv_path = '/content/drive/MyDrive/dzone_architecture_design_news.csv'\n","\n","# Cargar el archivo CSV\n","df = pd.read_csv(csv_path)\n","\n","# Eliminar filas donde Tag, Author y Date sean NaN\n","df_cleaned = df.dropna(subset=['Tag', 'Author', 'Date'], how='all')\n","\n","# Eliminar filas completamente vacías (que tienen solo valores NaN o están en blanco)\n","df_cleaned = df_cleaned.dropna(how='all')\n","\n","# Guardar el DataFrame limpio en un nuevo archivo CSV\n","cleaned_csv_path = '/content/drive/MyDrive/dzone_architecture_design_news_cleaned.csv'\n","df_cleaned.to_csv(cleaned_csv_path, index=False)\n","\n","# Mostrar las primeras filas del DataFrame limpio\n","print(df_cleaned.head(100))\n","\n","print(f\"CSV limpio guardado en: {cleaned_csv_path}\")"],"metadata":{"id":"IyHqaZEXGPCw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Montar Google Drive\n","from google.colab import drive\n","import pandas as pd\n","import re\n","from datetime import datetime\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Ruta del archivo CSV original en Google Drive\n","csv_path = '/content/drive/MyDrive/dzone_software_design_architecture.csv'\n","\n","\n","# Cargar el archivo CSV\n","df = pd.read_csv(csv_path)\n","\n","def clean_date(date_str):\n","    original_date = date_str\n","    # Eliminar 'Updated' y cualquier fecha adicional\n","    date_str = re.split(r'Updated', date_str)[-1].strip()\n","    date_str = re.split(r',', date_str)[0].strip()\n","\n","    # Buscar el año en la cadena original\n","    year_match = re.search(r'\\b\\d{4}\\b', original_date)\n","    year = year_match.group() if year_match else \"\"\n","\n","    # Convertir el formato de la fecha\n","    try:\n","        date_obj = datetime.strptime(date_str, '%B %d')\n","        return f\"{date_obj.strftime('%b %d').lower()} {year}\", original_date\n","    except ValueError:\n","        try:\n","            date_obj = datetime.strptime(date_str, '%b %d')\n","            return f\"{date_obj.strftime('%b %d').lower()} {year}\", original_date\n","        except ValueError:\n","            # Si no se puede parsear, intentar extraer mes y día\n","            month_day_match = re.search(r'([A-Za-z]+)\\s+(\\d{1,2})', date_str)\n","            if month_day_match and year:\n","                month, day = month_day_match.groups()\n","                return f\"{month[:3].lower()} {day.zfill(2)} {year}\", original_date\n","            else:\n","                return date_str, original_date  # Devolver la cadena original si no se puede parsear\n","\n","# Aplicar la función de limpieza a la columna 'Date'\n","df['CleanedDate'], df['OriginalDate'] = zip(*df['Date'].apply(clean_date))\n","\n","# Guardar el DataFrame con la columna 'Date' limpia en un nuevo archivo CSV\n","cleaned_csv_path = '/content/drive/MyDrive/dzone_architecture_design_news_date_cleaned.csv'\n","df.to_csv(cleaned_csv_path, index=False)\n","\n","# Mostrar las primeras filas del DataFrame con la columna 'Date' original y limpia\n","print(df[['OriginalDate', 'CleanedDate']].head(20))\n","\n","print(f\"CSV con la columna 'Date' limpia guardado en: {cleaned_csv_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBRzmN4biaF5","executionInfo":{"status":"ok","timestamp":1729456446878,"user_tz":180,"elapsed":4190,"user":{"displayName":"Fernando Muraca","userId":"00342931229691733138"}},"outputId":"965a80a0-492e-4f9c-ed74-db75e7d5b0e9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","               OriginalDate  CleanedDate\n","0          October 14, 2024  oct 14 2024\n","1          October 14, 2024  oct 14 2024\n","2          October 14, 2024  oct 14 2024\n","3          October 14, 2024  oct 14 2024\n","4          October 11, 2024  oct 11 2024\n","5          October 11, 2024  oct 11 2024\n","6          October 10, 2024  oct 10 2024\n","7          October 10, 2024  oct 10 2024\n","8           October 9, 2024  oct 09 2024\n","9           October 9, 2024  oct 09 2024\n","10          October 9, 2024  oct 09 2024\n","11          October 9, 2024  oct 09 2024\n","12  Updated October 9, 2024  oct 09 2024\n","13          October 9, 2024  oct 09 2024\n","14          October 9, 2024  oct 09 2024\n","15          October 8, 2024  oct 08 2024\n","16          October 8, 2024  oct 08 2024\n","17          October 8, 2024  oct 08 2024\n","18          October 8, 2024  oct 08 2024\n","19          October 8, 2024  oct 08 2024\n","CSV con la columna 'Date' limpia guardado en: /content/drive/MyDrive/dzone_architecture_design_news_date_cleaned.csv\n"]}]},{"cell_type":"code","source":["# Montar Google Drive\n","from google.colab import drive\n","import pandas as pd\n","import re\n","from datetime import datetime\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Ruta del archivo CSV original en Google Drive\n","csv_path = '/content/drive/MyDrive/dzone_software_design_architecture.csv'\n","\n","\n","# Cargar el archivo CSV\n","df = pd.read_csv(csv_path)\n","\n","def clean_date(date_str):\n","    original_date = date_str\n","    # Eliminar 'Updated' y cualquier fecha adicional\n","    date_str = re.split(r'Updated', date_str)[-1].strip()\n","    date_str = re.split(r',', date_str)[0].strip()\n","\n","    # Buscar el año en la cadena original\n","    year_match = re.search(r'\\b\\d{4}\\b', original_date)\n","    year = year_match.group() if year_match else \"\"\n","\n","    # Convertir el formato de la fecha\n","    try:\n","        date_obj = datetime.strptime(date_str, '%B %d')\n","        return f\"{date_obj.strftime('%b %d').lower()} {year}\", original_date\n","    except ValueError:\n","        try:\n","            date_obj = datetime.strptime(date_str, '%b %d')\n","            return f\"{date_obj.strftime('%b %d').lower()} {year}\", original_date\n","        except ValueError:\n","            # Si no se puede parsear, intentar extraer mes y día\n","            month_day_match = re.search(r'([A-Za-z]+)\\s+(\\d{1,2})', date_str)\n","            if month_day_match and year:\n","                month, day = month_day_match.groups()\n","                return f\"{month[:3].lower()} {day.zfill(2)} {year}\", original_date\n","            else:\n","                return date_str, original_date  # Devolver la cadena original si no se puede parsear\n","\n","# Aplicar la función de limpieza a la columna 'Date'\n","df['CleanedDate'], df['OriginalDate'] = zip(*df['Date'].apply(clean_date))\n","\n","# Guardar la fecha limpia en la columna 'Date' original\n","df['Date'] = df['CleanedDate']\n","\n","# Eliminar las columnas temporales\n","df = df.drop(columns=['CleanedDate', 'OriginalDate'])\n","\n","# Guardar el DataFrame con la columna 'Date' limpia en un nuevo archivo CSV\n","cleaned_csv_path = '/content/drive/MyDrive/dzone_architecture_design_news_date_cleaned.csv'\n","df.to_csv(cleaned_csv_path, index=False)\n","\n","# Mostrar las primeras filas del DataFrame con la columna 'Date' limpia\n","print(df[['Date']].head(20))\n","\n","print(f\"CSV con la columna 'Date' limpia guardado en: {cleaned_csv_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hp-hOMGSn5Vz","executionInfo":{"status":"ok","timestamp":1729456650631,"user_tz":180,"elapsed":4118,"user":{"displayName":"Fernando Muraca","userId":"00342931229691733138"}},"outputId":"5822cc25-7062-4227-c76a-c62ed330c7be"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","           Date\n","0   oct 14 2024\n","1   oct 14 2024\n","2   oct 14 2024\n","3   oct 14 2024\n","4   oct 11 2024\n","5   oct 11 2024\n","6   oct 10 2024\n","7   oct 10 2024\n","8   oct 09 2024\n","9   oct 09 2024\n","10  oct 09 2024\n","11  oct 09 2024\n","12  oct 09 2024\n","13  oct 09 2024\n","14  oct 09 2024\n","15  oct 08 2024\n","16  oct 08 2024\n","17  oct 08 2024\n","18  oct 08 2024\n","19  oct 08 2024\n","CSV con la columna 'Date' limpia guardado en: /content/drive/MyDrive/dzone_architecture_design_news_date_cleaned.csv\n"]}]},{"cell_type":"code","source":["# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Cargar el CSV final y mostrar información\n","df = pd.read_csv('/content/drive/MyDrive/infoq_architecture_design_news.csv')\n","\n","# Mostrar las primeras filas del DataFrame\n","print(df.head())\n","\n","# Mostrar información sobre el DataFrame\n","print(df.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"69JUcwBqIUS7","executionInfo":{"status":"error","timestamp":1728055501893,"user_tz":180,"elapsed":20743,"user":{"displayName":"Fernando Muraca","userId":"00342931229691733138"}},"outputId":"3daaeb15-0e06-46ee-d835-24c3bb79c2d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2563316321f5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Cargar el CSV final y mostrar información\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/infoq_architecture_design_news.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Mostrar las primeras filas del DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRjQc0Yj//a7lQklRlQQS7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}